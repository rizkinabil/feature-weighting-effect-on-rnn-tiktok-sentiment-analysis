{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer #Count Vector Space Model\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn import metrics #Matrix Builder\n",
    "from sklearn.model_selection import KFold #Import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score,multilabel_confusion_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_`, skiprows=[i for i in range(1, 1000) ]`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>at</th>\n",
       "      <th>label</th>\n",
       "      <th>cleansing</th>\n",
       "      <th>case_folding</th>\n",
       "      <th>no_unwanted</th>\n",
       "      <th>tokenize</th>\n",
       "      <th>normalization</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>stemming</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Keren</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-04-14 19:21:43</td>\n",
       "      <td>1</td>\n",
       "      <td>Keren</td>\n",
       "      <td>keren</td>\n",
       "      <td>keren</td>\n",
       "      <td>['keren']</td>\n",
       "      <td>['keren']</td>\n",
       "      <td>['keren']</td>\n",
       "      <td>['keren']</td>\n",
       "      <td>keren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Woy tiktok menangis gw event mlbb creator base...</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-04-07 23:01:39</td>\n",
       "      <td>1</td>\n",
       "      <td>Woy tiktok menangis gw event mlbb creator base...</td>\n",
       "      <td>woy tiktok menangis gw event mlbb creator base...</td>\n",
       "      <td>woy tiktok menangis gw event mlbb creator base...</td>\n",
       "      <td>['woy', 'tiktok', 'menangis', 'gw', 'event', '...</td>\n",
       "      <td>['oi', 'tiktok', 'menangis', 'gue', 'event', '...</td>\n",
       "      <td>['tiktok', 'menangis', 'gue', 'event', 'mlbb',...</td>\n",
       "      <td>['tiktok', 'menang', 'gue', 'event', 'mlbb', '...</td>\n",
       "      <td>tiktok menang gue event mlbb creator base gue ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Halo disini saya ingin menyampaikan kepada and...</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-04-07 20:13:21</td>\n",
       "      <td>1</td>\n",
       "      <td>Halo disini saya ingin menyampaikan kepada and...</td>\n",
       "      <td>halo disini saya ingin menyampaikan kepada and...</td>\n",
       "      <td>halo disini saya ingin menyampaikan kepada and...</td>\n",
       "      <td>['halo', 'disini', 'saya', 'ingin', 'menyampai...</td>\n",
       "      <td>['halo', 'di sini', 'saya', 'ingin', 'menyampa...</td>\n",
       "      <td>['di sini', 'membuka', 'komen', 'lag', 'koneks...</td>\n",
       "      <td>['di sini', 'buka', 'komen', 'lag', 'koneksi',...</td>\n",
       "      <td>di sini buka komen lag koneksi internet bagus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jangan mau main tiktokla paket kuota cpt hbis ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-04-11 17:06:47</td>\n",
       "      <td>-1</td>\n",
       "      <td>Jangan mau main tiktokla paket kuota cpt hbis ...</td>\n",
       "      <td>jangan mau main tiktokla paket kuota cpt hbis ...</td>\n",
       "      <td>jangan mau main tiktokla paket kuota cpt hbis ...</td>\n",
       "      <td>['jangan', 'mau', 'main', 'tiktokla', 'paket',...</td>\n",
       "      <td>['jangan', 'mau', 'main', 'tiktokla', 'paket',...</td>\n",
       "      <td>['main', 'tiktokla', 'paket', 'kuota', 'cepat'...</td>\n",
       "      <td>['main', 'tiktokla', 'paket', 'kuota', 'cepat'...</td>\n",
       "      <td>main tiktokla paket kuota cepat habis potong k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sangat menghibur asyik dan seru</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-04-13 21:08:45</td>\n",
       "      <td>1</td>\n",
       "      <td>Sangat menghibur asyik dan seru</td>\n",
       "      <td>sangat menghibur asyik dan seru</td>\n",
       "      <td>sangat menghibur asyik dan seru</td>\n",
       "      <td>['sangat', 'menghibur', 'asyik', 'dan', 'seru']</td>\n",
       "      <td>['sangat', 'menghibur', 'asyik', 'dan', 'seru']</td>\n",
       "      <td>['menghibur', 'seru']</td>\n",
       "      <td>['hibur', 'seru']</td>\n",
       "      <td>hibur seru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  score   \n",
       "0                                              Keren      5  \\\n",
       "1  Woy tiktok menangis gw event mlbb creator base...      5   \n",
       "2  Halo disini saya ingin menyampaikan kepada and...      4   \n",
       "3  Jangan mau main tiktokla paket kuota cpt hbis ...      2   \n",
       "4                    Sangat menghibur asyik dan seru      5   \n",
       "\n",
       "                    at  label   \n",
       "0  2023-04-14 19:21:43      1  \\\n",
       "1  2023-04-07 23:01:39      1   \n",
       "2  2023-04-07 20:13:21      1   \n",
       "3  2023-04-11 17:06:47     -1   \n",
       "4  2023-04-13 21:08:45      1   \n",
       "\n",
       "                                           cleansing   \n",
       "0                                              Keren  \\\n",
       "1  Woy tiktok menangis gw event mlbb creator base...   \n",
       "2  Halo disini saya ingin menyampaikan kepada and...   \n",
       "3  Jangan mau main tiktokla paket kuota cpt hbis ...   \n",
       "4                    Sangat menghibur asyik dan seru   \n",
       "\n",
       "                                        case_folding   \n",
       "0                                              keren  \\\n",
       "1  woy tiktok menangis gw event mlbb creator base...   \n",
       "2  halo disini saya ingin menyampaikan kepada and...   \n",
       "3  jangan mau main tiktokla paket kuota cpt hbis ...   \n",
       "4                    sangat menghibur asyik dan seru   \n",
       "\n",
       "                                         no_unwanted   \n",
       "0                                              keren  \\\n",
       "1  woy tiktok menangis gw event mlbb creator base...   \n",
       "2  halo disini saya ingin menyampaikan kepada and...   \n",
       "3  jangan mau main tiktokla paket kuota cpt hbis ...   \n",
       "4                    sangat menghibur asyik dan seru   \n",
       "\n",
       "                                            tokenize   \n",
       "0                                          ['keren']  \\\n",
       "1  ['woy', 'tiktok', 'menangis', 'gw', 'event', '...   \n",
       "2  ['halo', 'disini', 'saya', 'ingin', 'menyampai...   \n",
       "3  ['jangan', 'mau', 'main', 'tiktokla', 'paket',...   \n",
       "4    ['sangat', 'menghibur', 'asyik', 'dan', 'seru']   \n",
       "\n",
       "                                       normalization   \n",
       "0                                          ['keren']  \\\n",
       "1  ['oi', 'tiktok', 'menangis', 'gue', 'event', '...   \n",
       "2  ['halo', 'di sini', 'saya', 'ingin', 'menyampa...   \n",
       "3  ['jangan', 'mau', 'main', 'tiktokla', 'paket',...   \n",
       "4    ['sangat', 'menghibur', 'asyik', 'dan', 'seru']   \n",
       "\n",
       "                                           stopwords   \n",
       "0                                          ['keren']  \\\n",
       "1  ['tiktok', 'menangis', 'gue', 'event', 'mlbb',...   \n",
       "2  ['di sini', 'membuka', 'komen', 'lag', 'koneks...   \n",
       "3  ['main', 'tiktokla', 'paket', 'kuota', 'cepat'...   \n",
       "4                              ['menghibur', 'seru']   \n",
       "\n",
       "                                            stemming   \n",
       "0                                          ['keren']  \\\n",
       "1  ['tiktok', 'menang', 'gue', 'event', 'mlbb', '...   \n",
       "2  ['di sini', 'buka', 'komen', 'lag', 'koneksi',...   \n",
       "3  ['main', 'tiktokla', 'paket', 'kuota', 'cepat'...   \n",
       "4                                  ['hibur', 'seru']   \n",
       "\n",
       "                                               clean  \n",
       "0                                              keren  \n",
       "1  tiktok menang gue event mlbb creator base gue ...  \n",
       "2  di sini buka komen lag koneksi internet bagus ...  \n",
       "3  main tiktokla paket kuota cepat habis potong k...  \n",
       "4                                         hibur seru  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\kuliah\\THE ONLY TA THINGS\\DATA\\data clean\\cleaned_15000_data_sample.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       " 1    6315\n",
       "-1    1169\n",
       " 0     354\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and labels\n",
    "df['review_clean'] = df['clean'].astype(str)\n",
    "reviews = df['review_clean'].values\n",
    "\n",
    "labels = pd.get_dummies(df['label']).values.astype(int)\n",
    "\n",
    "\n",
    "# convert labels to one-hot encoding\n",
    "# labels = tf.keras.utils.to_categorical(df['label'], num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(reviews,labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tf-idf vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "train_tfidf_features = tfidf_vectorizer.fit_transform(x_train).toarray()\n",
    "test_tfidf_features = tfidf_vectorizer.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(i) for i in reviews])\n",
    "# max_length = 3\n",
    "# Pad sequences to have equal length\n",
    "X_train_padded = pad_sequences(train_tfidf_features, maxlen=max_length, padding='post', truncating='post')\n",
    "X_test_padded = pad_sequences(test_tfidf_features, maxlen=max_length, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train padded shape:  (5486, 523)\n",
      "X_test padded shape:  (2352, 523)\n",
      "y_train shape:  (5486, 3)\n",
      "y_test shape:  (2352, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train padded shape: \", X_train_padded.shape)\n",
    "print(\"X_test padded shape: \", X_test_padded.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf lalu split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tf-idf vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(reviews).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tokenizer\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "sequences = tokenizer.texts_to_sequences(reviews)\n",
    "\n",
    "\n",
    "\n",
    "# pad sequence\n",
    "padded_sequences = pad_sequences(sequences, maxlen=50, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine sequence and tf-idf features\n",
    "combined_features = tf.concat([tf.cast(tf.constant(tfidf_features), tf.float32), tf.cast(tf.constant(padded_sequences),  tf.float32)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences\n",
    "max_length = max([len(i) for i in combined_features])\n",
    "combined_features_in_max_length = tf.keras.preprocessing.sequence.pad_sequences(combined_features, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(combined_features_in_max_length, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, lstm_units, num_classes, dropout_rate=0.2):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding_layer = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        # self.bi_lstm_layer = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units))\n",
    "        self.lstm = tf.keras.layers.LSTM(lstm_units, dropout=dropout_rate, recurrent_dropout=dropout_rate)\n",
    "        self.dense_layer = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        # self.output_layer = tf.keras.layers.Dense(num_classes, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.embedding_layer(inputs)\n",
    "        x = self.lstm(x)\n",
    "        # x = self.bi_lstm_layer(x)\n",
    "        x = self.dense_layer(x)\n",
    "        # output = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uji coba k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split data into K folds\n",
    "kf = KFold(n_splits=3, random_state=0, shuffle = True)\n",
    "\n",
    "# # shuffle the data\n",
    "# indices = np.arange(len(combined_features))\n",
    "# np.random.shuffle(indices)\n",
    "# combined_features_data = combined_features[indices]\n",
    "# labels = labels[indices]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kfold dengan split di luar loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "115/115 [==============================] - 91s 750ms/step - loss: 0.6448 - accuracy: 0.8023 - val_loss: 0.6053 - val_accuracy: 0.8054\n",
      "Epoch 2/5\n",
      "115/115 [==============================] - 75s 654ms/step - loss: 0.5974 - accuracy: 0.8083 - val_loss: 0.6021 - val_accuracy: 0.8054\n",
      "Epoch 3/5\n",
      "115/115 [==============================] - 80s 692ms/step - loss: 0.5965 - accuracy: 0.8083 - val_loss: 0.6021 - val_accuracy: 0.8054\n",
      "Epoch 4/5\n",
      "115/115 [==============================] - 76s 661ms/step - loss: 0.6005 - accuracy: 0.8083 - val_loss: 0.6003 - val_accuracy: 0.8054\n",
      "Epoch 5/5\n",
      "115/115 [==============================] - 78s 681ms/step - loss: 0.5972 - accuracy: 0.8083 - val_loss: 0.6024 - val_accuracy: 0.8054\n",
      "74/74 [==============================] - 7s 97ms/step - loss: 0.6029 - accuracy: 0.8019\n",
      "Fold 1: accuracy: 80.19%\n",
      "Epoch 1/5\n",
      "115/115 [==============================] - 79s 655ms/step - loss: 0.6497 - accuracy: 0.7979 - val_loss: 0.5795 - val_accuracy: 0.8168\n",
      "Epoch 2/5\n",
      "115/115 [==============================] - 71s 615ms/step - loss: 0.6133 - accuracy: 0.8026 - val_loss: 0.5777 - val_accuracy: 0.8168\n",
      "Epoch 3/5\n",
      "115/115 [==============================] - 76s 665ms/step - loss: 0.6099 - accuracy: 0.8026 - val_loss: 0.5792 - val_accuracy: 0.8168\n",
      "Epoch 4/5\n",
      "115/115 [==============================] - 77s 673ms/step - loss: 0.6102 - accuracy: 0.8026 - val_loss: 0.5790 - val_accuracy: 0.8168\n",
      "Epoch 5/5\n",
      "115/115 [==============================] - 72s 623ms/step - loss: 0.6097 - accuracy: 0.8026 - val_loss: 0.5806 - val_accuracy: 0.8168\n",
      "74/74 [==============================] - 6s 84ms/step - loss: 0.6028 - accuracy: 0.8019\n",
      "Fold 2: accuracy: 80.19%\n",
      "Epoch 1/5\n",
      "115/115 [==============================] - 73s 602ms/step - loss: 0.6350 - accuracy: 0.8040 - val_loss: 0.6195 - val_accuracy: 0.7998\n",
      "Epoch 2/5\n",
      "115/115 [==============================] - 71s 620ms/step - loss: 0.5917 - accuracy: 0.8111 - val_loss: 0.6140 - val_accuracy: 0.7998\n",
      "Epoch 3/5\n",
      "115/115 [==============================] - 71s 619ms/step - loss: 0.5918 - accuracy: 0.8111 - val_loss: 0.6186 - val_accuracy: 0.7998\n",
      "Epoch 4/5\n",
      "115/115 [==============================] - 77s 671ms/step - loss: 0.5912 - accuracy: 0.8111 - val_loss: 0.6175 - val_accuracy: 0.7998\n",
      "Epoch 5/5\n",
      "115/115 [==============================] - 79s 683ms/step - loss: 0.5923 - accuracy: 0.8111 - val_loss: 0.6176 - val_accuracy: 0.7998\n",
      "74/74 [==============================] - 7s 93ms/step - loss: 0.6013 - accuracy: 0.8019\n",
      "Fold 3: accuracy: 80.19%\n"
     ]
    }
   ],
   "source": [
    "# Loop through each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_padded, y_train)):\n",
    "    \n",
    "    # Split train data into train and validation sets\n",
    "    x_train_fold = X_train_padded[train_idx]\n",
    "    y_train_fold = y_train[train_idx]\n",
    "    x_val_fold = X_train_padded[val_idx]\n",
    "    y_val_fold = y_train[val_idx]\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "    # build and compile the model\n",
    "    model = RNNModel(vocab_size=10000, embedding_dim=32, lstm_units=64, num_classes=3)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # train the model\n",
    "    history = model.fit(x_train_fold, y_train_fold, epochs=5, batch_size=32, validation_data=(x_val_fold, y_val_fold))\n",
    "\n",
    "    # evaluate the model on test set\n",
    "    score = model.evaluate(X_test_padded, y_test, batch_size=32, verbose=1)\n",
    "    print(\"Fold %d: %s: %.2f%%\" % (fold+1, model.metrics_names[1], score[1]*100))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 7s 92ms/step\n",
      "[[   0    0  368]\n",
      " [   0    0   98]\n",
      " [   0    0 1886]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       368\n",
      "           1       0.00      0.00      0.00        98\n",
      "           2       0.80      1.00      0.89      1886\n",
      "\n",
      "    accuracy                           0.80      2352\n",
      "   macro avg       0.27      0.33      0.30      2352\n",
      "weighted avg       0.64      0.80      0.71      2352\n",
      "\n",
      "Precision:  0.2672902494331066\n",
      "Recall:  0.3333333333333333\n",
      "F1:  0.29668082428818626\n",
      "Accuracy:  0.8018707482993197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels for the testing data\n",
    "label_pred_prob = model.predict(X_test_padded)\n",
    "label_pred = label_pred_prob.argmax(axis=1)\n",
    "label_test_one_dim = np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "print(confusion_matrix(label_test_one_dim, label_pred))\n",
    "print(classification_report(label_test_one_dim, label_pred))\n",
    "print(\"Precision: \",precision_score(label_test_one_dim, label_pred, average=\"macro\"))\n",
    "print(\"Recall: \",recall_score(label_test_one_dim, label_pred, average=\"macro\"))\n",
    "print(\"F1: \",f1_score(label_test_one_dim, label_pred,  average=\"macro\"))\n",
    "print(\"Accuracy: \",accuracy_score(label_test_one_dim, label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(label_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_test_one_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_value = pd.DataFrame(label_test_one_dim)\n",
    "label_value.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train: \", x_train.shape)\n",
    "print(\"x_test: \", x_test.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kfold dengan split di dalam loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over each fold\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(tfidf_features)):\n",
    "  print(\"fold: \", fold+1)\n",
    "  # split data into train and test set\n",
    "  x_train, x_test = tfidf_features[train_index], tfidf_features[test_index]\n",
    "  y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "  # build and compile the model\n",
    "  model = RNNModel(vocab_size=10000, embedding_dim=32, lstm_units=64, num_classes=3)\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "  # train the model\n",
    "  history = model.fit(tfidf_features, labels, epochs=5, batch_size=32)\n",
    "\n",
    "  # evaluate the model on test set\n",
    "  score = model.evaluate(x_test, y_test, batch_size=32, verbose=1)\n",
    "  print(\"Fold %d: %s: %.2f%%\" % (fold, model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uji coba 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(vocab_size=5000, embedding_dim=32, lstm_units=64, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model.fit(X_train_vec, y_train, epochs=10, batch_size=32, validation_data=(X_test_vec, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the testing data\n",
    "label_pred_prob = model.predict(test_tfidf_features)\n",
    "label_pred = label_pred_prob.argmax(axis=1)-1\n",
    "label_test_one_dim = np.argmax(y_test, axis=1)-1\n",
    "\n",
    "\n",
    "# # Hitung confusion matrix untuk setiap label\n",
    "# cm = multilabel_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# print(\"Confusion matrix untuk label 1:\")\n",
    "# print(cm[0])\n",
    "\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(label_test_one_dim, label_pred))\n",
    "print(\"Precision: \",precision_score(label_test_one_dim, label_pred, average=\"macro\"))\n",
    "print(\"Recall: \",recall_score(label_test_one_dim, label_pred, average=\"macro\"))\n",
    "print(\"F1: \",f1_score(label_test_one_dim, label_pred,  average=\"macro\"))\n",
    "print(\"Accuracy: \",accuracy_score(label_test_one_dim, label_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_value = pd.DataFrame(label_test_one_dim)\n",
    "label_value.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
