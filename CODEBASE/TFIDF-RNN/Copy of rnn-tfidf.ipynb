{"cells":[{"cell_type":"markdown","metadata":{"id":"o3TlNdr582a1"},"source":["## sentiment analysis - TFIDF feature weighting with RNN classification"]},{"cell_type":"markdown","metadata":{"id":"DzmSGut882bD"},"source":["`Term Weighting = TFIDF`"]},{"cell_type":"markdown","metadata":{"id":"aiuN7A-q82bE"},"source":["# Libraries"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":4265,"status":"ok","timestamp":1681576683112,"user":{"displayName":"Rizki Nabil Aufa","userId":"11323752463281049119"},"user_tz":-420},"id":"_ZQ21zuh82bF"},"outputs":[],"source":["import pandas as pd\n","import itertools\n","import matplotlib.pyplot as plt\n","\n","import numpy as np\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer #Count Vector Space Model\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn import metrics #Matrix Builder\n","from sklearn.metrics import accuracy_score  \n","from sklearn.model_selection import KFold #Import KFold\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n","from scipy.sparse import csr_matrix\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Embedding, Dropout\n","\n","from keras import Sequential\n","from keras.models import load_model\n","\n","from sklearn.model_selection import KFold\n","\n","import tensorflow as tf"]},{"cell_type":"markdown","metadata":{"id":"xl7C8p0N82bJ"},"source":["# Load Dataset"]},{"cell_type":"markdown","metadata":{"id":"EYhXqFAX82bJ"},"source":["_`preprocessed dataset`_"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":458},"executionInfo":{"elapsed":368,"status":"ok","timestamp":1681576736256,"user":{"displayName":"Rizki Nabil Aufa","userId":"11323752463281049119"},"user_tz":-420},"id":"Ex8XAjwb82bK","outputId":"f839b7ef-0246-4525-9574-5cafd6d83955"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content</th>\n","      <th>score</th>\n","      <th>at</th>\n","      <th>label</th>\n","      <th>cleansing</th>\n","      <th>case_folding</th>\n","      <th>no_unwanted</th>\n","      <th>tokenize</th>\n","      <th>normalization</th>\n","      <th>stopwords</th>\n","      <th>stemming</th>\n","      <th>clean</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Keren</td>\n","      <td>5</td>\n","      <td>2023-04-14 19:21:43</td>\n","      <td>1</td>\n","      <td>Keren</td>\n","      <td>keren</td>\n","      <td>keren</td>\n","      <td>['keren']</td>\n","      <td>['keren']</td>\n","      <td>['keren']</td>\n","      <td>['keren']</td>\n","      <td>keren</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Woy tiktok menangis gw event mlbb creator base...</td>\n","      <td>5</td>\n","      <td>2023-04-07 23:01:39</td>\n","      <td>1</td>\n","      <td>Woy tiktok menangis gw event mlbb creator base...</td>\n","      <td>woy tiktok menangis gw event mlbb creator base...</td>\n","      <td>woy tiktok menangis gw event mlbb creator base...</td>\n","      <td>['woy', 'tiktok', 'menangis', 'gw', 'event', '...</td>\n","      <td>['oi', 'tiktok', 'menangis', 'gue', 'event', '...</td>\n","      <td>['tiktok', 'menangis', 'gue', 'event', 'mlbb',...</td>\n","      <td>['tiktok', 'menang', 'gue', 'event', 'mlbb', '...</td>\n","      <td>tiktok menang gue event mlbb creator base gue ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Halo disini saya ingin menyampaikan kepada and...</td>\n","      <td>4</td>\n","      <td>2023-04-07 20:13:21</td>\n","      <td>1</td>\n","      <td>Halo disini saya ingin menyampaikan kepada and...</td>\n","      <td>halo disini saya ingin menyampaikan kepada and...</td>\n","      <td>halo disini saya ingin menyampaikan kepada and...</td>\n","      <td>['halo', 'disini', 'saya', 'ingin', 'menyampai...</td>\n","      <td>['halo', 'di sini', 'saya', 'ingin', 'menyampa...</td>\n","      <td>['di sini', 'membuka', 'komen', 'lag', 'koneks...</td>\n","      <td>['di sini', 'buka', 'komen', 'lag', 'koneksi',...</td>\n","      <td>di sini buka komen lag koneksi internet bagus ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Jangan mau main tiktokla paket kuota cpt hbis ...</td>\n","      <td>2</td>\n","      <td>2023-04-11 17:06:47</td>\n","      <td>-1</td>\n","      <td>Jangan mau main tiktokla paket kuota cpt hbis ...</td>\n","      <td>jangan mau main tiktokla paket kuota cpt hbis ...</td>\n","      <td>jangan mau main tiktokla paket kuota cpt hbis ...</td>\n","      <td>['jangan', 'mau', 'main', 'tiktokla', 'paket',...</td>\n","      <td>['jangan', 'mau', 'main', 'tiktokla', 'paket',...</td>\n","      <td>['main', 'tiktokla', 'paket', 'kuota', 'cepat'...</td>\n","      <td>['main', 'tiktokla', 'paket', 'kuota', 'cepat'...</td>\n","      <td>main tiktokla paket kuota cepat habis potong k...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sangat menghibur asyik dan seru</td>\n","      <td>5</td>\n","      <td>2023-04-13 21:08:45</td>\n","      <td>1</td>\n","      <td>Sangat menghibur asyik dan seru</td>\n","      <td>sangat menghibur asyik dan seru</td>\n","      <td>sangat menghibur asyik dan seru</td>\n","      <td>['sangat', 'menghibur', 'asyik', 'dan', 'seru']</td>\n","      <td>['sangat', 'menghibur', 'asyik', 'dan', 'seru']</td>\n","      <td>['menghibur', 'seru']</td>\n","      <td>['hibur', 'seru']</td>\n","      <td>hibur seru</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7833</th>\n","      <td>Bagus</td>\n","      <td>5</td>\n","      <td>2023-04-12 07:08:12</td>\n","      <td>1</td>\n","      <td>Bagus</td>\n","      <td>bagus</td>\n","      <td>bagus</td>\n","      <td>['bagus']</td>\n","      <td>['bagus']</td>\n","      <td>['bagus']</td>\n","      <td>['bagus']</td>\n","      <td>bagus</td>\n","    </tr>\n","    <tr>\n","      <th>7834</th>\n","      <td>Sangat dramatis dan seru</td>\n","      <td>5</td>\n","      <td>2023-04-07 04:51:48</td>\n","      <td>1</td>\n","      <td>Sangat dramatis dan seru</td>\n","      <td>sangat dramatis dan seru</td>\n","      <td>sangat dramatis dan seru</td>\n","      <td>['sangat', 'dramatis', 'dan', 'seru']</td>\n","      <td>['sangat', 'dramatis', 'dan', 'seru']</td>\n","      <td>['dramatis', 'seru']</td>\n","      <td>['dramatis', 'seru']</td>\n","      <td>dramatis seru</td>\n","    </tr>\n","    <tr>\n","      <th>7835</th>\n","      <td>Baik buat mata +18</td>\n","      <td>5</td>\n","      <td>2023-04-09 10:05:38</td>\n","      <td>1</td>\n","      <td>Baik buat mata</td>\n","      <td>baik buat mata</td>\n","      <td>baik buat mata</td>\n","      <td>['baik', 'buat', 'mata']</td>\n","      <td>['baik', 'buat', 'mata']</td>\n","      <td>[]</td>\n","      <td>[]</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7836</th>\n","      <td>min ini gimana gabisa masuk min ðŸ˜¦ðŸ˜¦</td>\n","      <td>1</td>\n","      <td>2023-04-10 18:09:14</td>\n","      <td>-1</td>\n","      <td>min ini gimana gabisa masuk min</td>\n","      <td>min ini gimana gabisa masuk min</td>\n","      <td>min ini gimana gabisa masuk min</td>\n","      <td>['min', 'ini', 'gimana', 'gabisa', 'masuk', 'm...</td>\n","      <td>['min', 'ini', 'bagaimana', 'enggak bisa', 'ma...</td>\n","      <td>['enggak bisa']</td>\n","      <td>['enggak bisa']</td>\n","      <td>enggak bisa</td>\n","    </tr>\n","    <tr>\n","      <th>7837</th>\n","      <td>Mantap</td>\n","      <td>5</td>\n","      <td>2023-04-11 05:33:06</td>\n","      <td>1</td>\n","      <td>Mantap</td>\n","      <td>mantap</td>\n","      <td>mantap</td>\n","      <td>['mantap']</td>\n","      <td>['mantap']</td>\n","      <td>['mantap']</td>\n","      <td>['mantap']</td>\n","      <td>mantap</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7838 rows Ã— 12 columns</p>\n","</div>"],"text/plain":["                                                content  score   \n","0                                                 Keren      5  \\\n","1     Woy tiktok menangis gw event mlbb creator base...      5   \n","2     Halo disini saya ingin menyampaikan kepada and...      4   \n","3     Jangan mau main tiktokla paket kuota cpt hbis ...      2   \n","4                       Sangat menghibur asyik dan seru      5   \n","...                                                 ...    ...   \n","7833                                              Bagus      5   \n","7834                           Sangat dramatis dan seru      5   \n","7835                                 Baik buat mata +18      5   \n","7836                 min ini gimana gabisa masuk min ðŸ˜¦ðŸ˜¦      1   \n","7837                                             Mantap      5   \n","\n","                       at  label   \n","0     2023-04-14 19:21:43      1  \\\n","1     2023-04-07 23:01:39      1   \n","2     2023-04-07 20:13:21      1   \n","3     2023-04-11 17:06:47     -1   \n","4     2023-04-13 21:08:45      1   \n","...                   ...    ...   \n","7833  2023-04-12 07:08:12      1   \n","7834  2023-04-07 04:51:48      1   \n","7835  2023-04-09 10:05:38      1   \n","7836  2023-04-10 18:09:14     -1   \n","7837  2023-04-11 05:33:06      1   \n","\n","                                              cleansing   \n","0                                                 Keren  \\\n","1     Woy tiktok menangis gw event mlbb creator base...   \n","2     Halo disini saya ingin menyampaikan kepada and...   \n","3     Jangan mau main tiktokla paket kuota cpt hbis ...   \n","4                       Sangat menghibur asyik dan seru   \n","...                                                 ...   \n","7833                                              Bagus   \n","7834                           Sangat dramatis dan seru   \n","7835                                    Baik buat mata    \n","7836                   min ini gimana gabisa masuk min    \n","7837                                             Mantap   \n","\n","                                           case_folding   \n","0                                                 keren  \\\n","1     woy tiktok menangis gw event mlbb creator base...   \n","2     halo disini saya ingin menyampaikan kepada and...   \n","3     jangan mau main tiktokla paket kuota cpt hbis ...   \n","4                       sangat menghibur asyik dan seru   \n","...                                                 ...   \n","7833                                              bagus   \n","7834                           sangat dramatis dan seru   \n","7835                                    baik buat mata    \n","7836                   min ini gimana gabisa masuk min    \n","7837                                             mantap   \n","\n","                                            no_unwanted   \n","0                                                 keren  \\\n","1     woy tiktok menangis gw event mlbb creator base...   \n","2     halo disini saya ingin menyampaikan kepada and...   \n","3     jangan mau main tiktokla paket kuota cpt hbis ...   \n","4                       sangat menghibur asyik dan seru   \n","...                                                 ...   \n","7833                                              bagus   \n","7834                           sangat dramatis dan seru   \n","7835                                    baik buat mata    \n","7836                   min ini gimana gabisa masuk min    \n","7837                                             mantap   \n","\n","                                               tokenize   \n","0                                             ['keren']  \\\n","1     ['woy', 'tiktok', 'menangis', 'gw', 'event', '...   \n","2     ['halo', 'disini', 'saya', 'ingin', 'menyampai...   \n","3     ['jangan', 'mau', 'main', 'tiktokla', 'paket',...   \n","4       ['sangat', 'menghibur', 'asyik', 'dan', 'seru']   \n","...                                                 ...   \n","7833                                          ['bagus']   \n","7834              ['sangat', 'dramatis', 'dan', 'seru']   \n","7835                           ['baik', 'buat', 'mata']   \n","7836  ['min', 'ini', 'gimana', 'gabisa', 'masuk', 'm...   \n","7837                                         ['mantap']   \n","\n","                                          normalization   \n","0                                             ['keren']  \\\n","1     ['oi', 'tiktok', 'menangis', 'gue', 'event', '...   \n","2     ['halo', 'di sini', 'saya', 'ingin', 'menyampa...   \n","3     ['jangan', 'mau', 'main', 'tiktokla', 'paket',...   \n","4       ['sangat', 'menghibur', 'asyik', 'dan', 'seru']   \n","...                                                 ...   \n","7833                                          ['bagus']   \n","7834              ['sangat', 'dramatis', 'dan', 'seru']   \n","7835                           ['baik', 'buat', 'mata']   \n","7836  ['min', 'ini', 'bagaimana', 'enggak bisa', 'ma...   \n","7837                                         ['mantap']   \n","\n","                                              stopwords   \n","0                                             ['keren']  \\\n","1     ['tiktok', 'menangis', 'gue', 'event', 'mlbb',...   \n","2     ['di sini', 'membuka', 'komen', 'lag', 'koneks...   \n","3     ['main', 'tiktokla', 'paket', 'kuota', 'cepat'...   \n","4                                 ['menghibur', 'seru']   \n","...                                                 ...   \n","7833                                          ['bagus']   \n","7834                               ['dramatis', 'seru']   \n","7835                                                 []   \n","7836                                    ['enggak bisa']   \n","7837                                         ['mantap']   \n","\n","                                               stemming   \n","0                                             ['keren']  \\\n","1     ['tiktok', 'menang', 'gue', 'event', 'mlbb', '...   \n","2     ['di sini', 'buka', 'komen', 'lag', 'koneksi',...   \n","3     ['main', 'tiktokla', 'paket', 'kuota', 'cepat'...   \n","4                                     ['hibur', 'seru']   \n","...                                                 ...   \n","7833                                          ['bagus']   \n","7834                               ['dramatis', 'seru']   \n","7835                                                 []   \n","7836                                    ['enggak bisa']   \n","7837                                         ['mantap']   \n","\n","                                                  clean  \n","0                                                 keren  \n","1     tiktok menang gue event mlbb creator base gue ...  \n","2     di sini buka komen lag koneksi internet bagus ...  \n","3     main tiktokla paket kuota cepat habis potong k...  \n","4                                            hibur seru  \n","...                                                 ...  \n","7833                                              bagus  \n","7834                                      dramatis seru  \n","7835                                                NaN  \n","7836                                        enggak bisa  \n","7837                                             mantap  \n","\n","[7838 rows x 12 columns]"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('D:\\kuliah\\THE ONLY TA THINGS\\DATA\\data clean\\cleaned_15000_data_sample.csv')\n","df"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":401,"status":"ok","timestamp":1681576748296,"user":{"displayName":"Rizki Nabil Aufa","userId":"11323752463281049119"},"user_tz":-420},"id":"d3mpSOzE82bP"},"outputs":[],"source":["df = df.dropna()\n","df = df.reset_index(drop=True)\n","# # df = df[df.stemming != '[]']"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1681576749024,"user":{"displayName":"Rizki Nabil Aufa","userId":"11323752463281049119"},"user_tz":-420},"id":"gwZjgThe82bR","outputId":"6f08d1d3-72fb-47f3-a6b8-7a2a9b53dbc5"},"outputs":[{"data":{"text/plain":["content          0\n","score            0\n","at               0\n","label            0\n","cleansing        0\n","case_folding     0\n","no_unwanted      0\n","tokenize         0\n","normalization    0\n","stopwords        0\n","stemming         0\n","clean            0\n","dtype: int64"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["df.isnull().sum()"]},{"cell_type":"markdown","metadata":{"id":"gzOGv5E182bT"},"source":["_`total label value`_"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":342,"status":"ok","timestamp":1681576757423,"user":{"displayName":"Rizki Nabil Aufa","userId":"11323752463281049119"},"user_tz":-420},"id":"Fuxa5t_782bU","outputId":"a86ab672-6939-447a-80d8-016cf6262f2b"},"outputs":[{"data":{"text/plain":["label\n"," 1    5738\n","-1    1118\n"," 0     329\n","Name: count, dtype: int64"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["df['label'].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"AQXYbw-Y82bX"},"source":["# TFIDF for feature weighting"]},{"cell_type":"markdown","metadata":{"id":"WexQP2p-82bX"},"source":["#### split data test data train"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1681576768899,"user":{"displayName":"Rizki Nabil Aufa","userId":"11323752463281049119"},"user_tz":-420},"id":"jzcLIXj982bi","outputId":"f04767e6-a540-46be-d4bf-3c7cb2b7e6a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]]\n"]}],"source":["tfidf_vect = TfidfVectorizer(use_idf = True ,max_features = 5000)\n","x = tfidf_vect.fit(df[\"stemming\"])\n","TFIDF = x.transform(df[\"stemming\"])\n","\n","TFIDF = TFIDF.toarray()\n","print(TFIDF)"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1681576771239,"user":{"displayName":"Rizki Nabil Aufa","userId":"11323752463281049119"},"user_tz":-420},"id":"MPpt5K3i9wCp"},"outputs":[],"source":["# tfidf_vect = TfidfVectorizer(use_idf = True ,max_features = 5000)\n","# x = tfidf_vect.fit(X_test)\n","# TFIDF_test = x.transform(X_test)\n","# TFIDF_test = TFIDF_test.toarray()"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1681576771240,"user":{"displayName":"Rizki Nabil Aufa","userId":"11323752463281049119"},"user_tz":-420},"id":"obeAQNQv97Ku"},"outputs":[],"source":["# from keras_preprocessing.sequence import pad_sequences\n","# maxlen = 121 # set the maximum sequence length to 121\n","# TFIDF_train = pad_sequences(TFIDF_train, maxlen=maxlen)\n","# TFIDF_test = pad_sequences(TFIDF_test, maxlen=maxlen)"]},{"cell_type":"markdown","metadata":{"id":"iR00lu6182bl"},"source":["_`Seperate label to its own array`_"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":774,"status":"ok","timestamp":1681576778733,"user":{"displayName":"Rizki Nabil Aufa","userId":"11323752463281049119"},"user_tz":-420},"id":"nWUh1Nqc82bl","outputId":"222f8243-554e-491f-e14d-e7bc1c151fd0"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 0, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 0, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 0, 1, 1, 1, 1, -1, 1, 1, 1, 0, -1, 1, 1, 1, 1, -1, 1, 1, 0, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 0, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 0, 1, 1, 1, 1, -1, 0, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 0, 1, -1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 0, 1, 1, 1, 1, 1, 1, -1, 1, -1, 0, 1, -1, 1, -1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, -1, 0, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, -1, 0, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, -1, -1, 0, 1, 0, 1, 1, 1, 0, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 0, 1, 0, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 0, 1, -1, 0, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 0, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 0, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, -1, -1, 0, -1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, -1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 0, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 0, 1, -1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 0, 1, 1, 1, -1, -1, 0, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 0, 1, 1, -1, 1, 1, 1, 1, 1, -1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 0, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 0, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 0, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, -1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, -1, 1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, -1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 0, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 0, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, -1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 0, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 0, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 0, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 0, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 0, 1, 0, 1, 1, 0, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, -1, 1, 1, 1, -1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 0, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 0, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 0, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, -1, -1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 0, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 0, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 0, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 0, 1, 1, 0, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, -1, 1, -1, -1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 0, 1, -1, 1, -1, 1, 1, 0, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, -1, 0, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 0, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 0, 1, -1, 1, 0, -1, 1, -1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0, 1, 1, 1, 1, 1, 0, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 0, 1, 1, -1, 1, 0, 1, 1, 0, 0, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 0, -1, 1, 1, 0, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 0, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 0, 1, -1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, -1, -1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 0, 0, 1, -1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 0, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 0, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 0, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, -1, -1, -1, -1, 1, 0, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 0, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 0, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 0, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 0, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 0, 1, -1, 1, 1, 1, -1, 1, 1, 0, 1, 1, -1, 0, 1, 0, 1, 1, -1, 1, 1, 1, 1, 1, 0, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 0, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 0, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 0, 1, 1, -1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 0, 1, 1, 0, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, -1, 1, 1, 1, 0, 1, 1, 1, 1, 0, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 0, -1, 1, -1, 0, -1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 0, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 0, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 0, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 0, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, -1, 1, 1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 0, 1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 0, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, -1, -1, -1, -1, -1, 0, 1, 1, 1, 1, -1, 0, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, -1, 1, -1, 1, 1, -1, -1, -1, 1, 0, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 0, 1, -1, 0, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 0, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 0, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 0, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 0, -1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 0, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, -1, 0, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 0, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, -1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 0, 0, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 0, 1, -1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 0, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 0, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 0, 1, 1, 1, -1, 1, 1, -1, -1, 1, 0, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 0, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 0, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 0, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 0, 1, -1, 1, 1, -1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 0, 1, 1, 1, 0, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 0, 1, 1, 1, 1, 1, 1, -1, -1, 0, -1, 0, -1, 1, 0, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 0, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, -1, 1, -1, -1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 0, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 0, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 0, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, -1, 1, 0, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 0, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 0, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, -1, 1, 0, 1, -1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 0, 1, 1, -1, 1, 1, 0, 1, 1, 1, 1, 0, 1, -1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 0, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 0, 1, -1, 1, 1, -1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 0, 0, 1, -1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 0, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, 1, 0, 1, 1, 1, -1, 1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, -1, 1, -1, 1, 1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, -1, 1]\n"]}],"source":["label = []\n","for data in df['label']:\n","    label.append(data)\n","kolom = label.pop\n","\n","print(label)"]},{"cell_type":"markdown","metadata":{"id":"9eZEpT6k82bp"},"source":["## Define RNN Model"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1681576781163,"user":{"displayName":"Rizki Nabil Aufa","userId":"11323752463281049119"},"user_tz":-420},"id":"m3NOpi5U82bq"},"outputs":[],"source":["# Define the RNN model\n","def build_model(input_dim):\n","    model = Sequential()\n","    model.add(LSTM(units=32, input_shape=(input_dim, 1)))\n","    # model.add(Dropout(0.5))\n","    model.add(Dense(units=3, activation='softmax'))\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"CoaQRA-z82br"},"source":["## implement w/ k-fold"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["# set up k-fold cross validation\n","num_folds = 2\n","kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","Fold 1/2\n","\n","Epoch 1/10\n"]},{"ename":"ValueError","evalue":"in user code:\n\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[40], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m y_train, y_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(label)[train_index], np\u001b[39m.\u001b[39marray(label)[test_index]\n\u001b[0;32m     14\u001b[0m model \u001b[39m=\u001b[39m build_model(input_dim\u001b[39m=\u001b[39mTFIDF\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[1;32m---> 15\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test))\n\u001b[0;32m     18\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     19\u001b[0m scores\u001b[39m.\u001b[39mappend(accuracy)\n","File \u001b[1;32mc:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filenz3hlh30.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n","\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n"]}],"source":["# train and evaluate model\n","fold = 0\n","scores = []\n","for train_index, test_index in kf.split(TFIDF):\n","    fold += 1\n","    print('\\n')\n","    print(f'Fold {fold}/{num_folds}\\n')\n","\n","    # split data into train and test sets\n","    X_train, X_test = TFIDF[train_index], TFIDF[test_index]\n","    y_train, y_test = np.array(label)[train_index], np.array(label)[test_index]\n","\n","\n","    model = build_model(input_dim=TFIDF.shape[1])\n","    model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n","\n","\n","    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n","    scores.append(accuracy)\n","\n","    print('Folds : %d | Cross-validation accuracy : %.4f | Max, Min : %.4f, %.4f' \n","            % (fold, np.mean(scores), max(scores), min(scores)))\n","#     print(\"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 1s 85ms/step\n","[[  0  24   0]\n"," [  0   8   0]\n"," [  0 117   0]]\n","              precision    recall  f1-score   support\n","\n","          -1       0.00      0.00      0.00        24\n","           0       0.05      1.00      0.10         8\n","           1       0.00      0.00      0.00       117\n","\n","    accuracy                           0.05       149\n","   macro avg       0.02      0.33      0.03       149\n","weighted avg       0.00      0.05      0.01       149\n","\n","Precision:  0.017897091722595078\n","Recall:  0.3333333333333333\n","F1:  0.03397027600849257\n","Accuracy:  0.053691275167785234\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["y_pred = model.predict(X_test).astype('int32')\n","y_pred = y_pred.argmax(axis=1)\n","\n","print(confusion_matrix(y_test, y_pred))\n","print(classification_report(y_test, y_pred))\n","print(\"Precision: \",precision_score(y_test, y_pred, average=\"macro\"))\n","print(\"Recall: \",recall_score(y_test, y_pred, average=\"macro\"))\n","print(\"F1: \",f1_score(y_test, y_pred,  average=\"macro\"))\n","print(\"Accuracy: \",accuracy_score(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"s0Z9BPRk82br","outputId":"ef5cd12b-1185-4942-fe33-c042c64c43b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","9/9 [==============================] - 6s 362ms/step - loss: 0.6897 - accuracy: 0.5522 - val_loss: 0.7064 - val_accuracy: 0.6333\n","Epoch 2/10\n","9/9 [==============================] - 3s 310ms/step - loss: 0.6638 - accuracy: 0.8097 - val_loss: 0.7663 - val_accuracy: 0.6333\n","Epoch 3/10\n","9/9 [==============================] - 3s 298ms/step - loss: 0.6533 - accuracy: 0.8097 - val_loss: 0.7536 - val_accuracy: 0.6333\n","Epoch 4/10\n","9/9 [==============================] - 3s 299ms/step - loss: 0.6466 - accuracy: 0.8097 - val_loss: 0.8438 - val_accuracy: 0.6333\n","Epoch 5/10\n","9/9 [==============================] - 3s 294ms/step - loss: 0.6554 - accuracy: 0.8097 - val_loss: 0.7986 - val_accuracy: 0.6333\n","Epoch 6/10\n","9/9 [==============================] - 3s 302ms/step - loss: 0.6414 - accuracy: 0.8097 - val_loss: 0.7974 - val_accuracy: 0.6333\n","Epoch 7/10\n","9/9 [==============================] - 3s 302ms/step - loss: 0.6331 - accuracy: 0.8097 - val_loss: 0.8389 - val_accuracy: 0.6333\n","Epoch 8/10\n","9/9 [==============================] - 3s 300ms/step - loss: 0.6416 - accuracy: 0.8097 - val_loss: 0.8504 - val_accuracy: 0.6333\n","Epoch 9/10\n","9/9 [==============================] - 3s 291ms/step - loss: 0.6564 - accuracy: 0.8097 - val_loss: 0.8180 - val_accuracy: 0.6333\n","Epoch 10/10\n","9/9 [==============================] - 3s 351ms/step - loss: 0.6439 - accuracy: 0.8097 - val_loss: 0.7548 - val_accuracy: 0.6333\n","Epoch 1/10\n","9/9 [==============================] - 6s 412ms/step - loss: 0.6884 - accuracy: 0.7052 - val_loss: 0.6805 - val_accuracy: 0.8000\n","Epoch 2/10\n","9/9 [==============================] - 3s 347ms/step - loss: 0.6627 - accuracy: 0.7910 - val_loss: 0.6847 - val_accuracy: 0.8000\n","Epoch 3/10\n","9/9 [==============================] - 3s 344ms/step - loss: 0.6789 - accuracy: 0.7910 - val_loss: 0.6642 - val_accuracy: 0.8000\n","Epoch 4/10\n","9/9 [==============================] - 3s 359ms/step - loss: 0.6608 - accuracy: 0.7910 - val_loss: 0.6623 - val_accuracy: 0.8000\n","Epoch 5/10\n","9/9 [==============================] - 3s 347ms/step - loss: 0.6623 - accuracy: 0.7910 - val_loss: 0.6583 - val_accuracy: 0.8000\n","Epoch 6/10\n","9/9 [==============================] - 3s 341ms/step - loss: 0.6565 - accuracy: 0.7910 - val_loss: 0.6586 - val_accuracy: 0.8000\n","Epoch 7/10\n","9/9 [==============================] - 3s 348ms/step - loss: 0.6555 - accuracy: 0.7910 - val_loss: 0.6585 - val_accuracy: 0.8000\n","Epoch 8/10\n","9/9 [==============================] - 3s 344ms/step - loss: 0.6532 - accuracy: 0.7910 - val_loss: 0.6588 - val_accuracy: 0.8000\n","Epoch 9/10\n","9/9 [==============================] - 3s 348ms/step - loss: 0.6572 - accuracy: 0.7910 - val_loss: 0.6589 - val_accuracy: 0.8000\n","Epoch 10/10\n","9/9 [==============================] - 3s 361ms/step - loss: 0.6615 - accuracy: 0.7910 - val_loss: 0.6632 - val_accuracy: 0.8000\n","Epoch 1/10\n","9/9 [==============================] - 6s 409ms/step - loss: 0.6894 - accuracy: 0.7164 - val_loss: 0.6551 - val_accuracy: 0.8667\n","Epoch 2/10\n","9/9 [==============================] - 3s 343ms/step - loss: 0.6731 - accuracy: 0.7836 - val_loss: 0.6026 - val_accuracy: 0.8667\n","Epoch 3/10\n","9/9 [==============================] - 3s 364ms/step - loss: 0.6789 - accuracy: 0.7836 - val_loss: 0.6268 - val_accuracy: 0.8667\n","Epoch 4/10\n","9/9 [==============================] - 3s 362ms/step - loss: 0.6630 - accuracy: 0.7836 - val_loss: 0.5751 - val_accuracy: 0.8667\n","Epoch 5/10\n","9/9 [==============================] - 3s 336ms/step - loss: 0.6843 - accuracy: 0.7836 - val_loss: 0.6086 - val_accuracy: 0.8667\n","Epoch 6/10\n","9/9 [==============================] - 3s 350ms/step - loss: 0.6662 - accuracy: 0.7836 - val_loss: 0.6293 - val_accuracy: 0.8667\n","Epoch 7/10\n","9/9 [==============================] - 3s 333ms/step - loss: 0.6704 - accuracy: 0.7836 - val_loss: 0.6219 - val_accuracy: 0.8667\n","Epoch 8/10\n","9/9 [==============================] - 3s 350ms/step - loss: 0.6663 - accuracy: 0.7836 - val_loss: 0.6153 - val_accuracy: 0.8667\n","Epoch 9/10\n","9/9 [==============================] - 3s 353ms/step - loss: 0.6728 - accuracy: 0.7836 - val_loss: 0.5946 - val_accuracy: 0.8667\n","Epoch 10/10\n","9/9 [==============================] - 3s 349ms/step - loss: 0.6637 - accuracy: 0.7836 - val_loss: 0.5875 - val_accuracy: 0.8667\n","Epoch 1/10\n","9/9 [==============================] - 6s 387ms/step - loss: 0.6886 - accuracy: 0.7052 - val_loss: 0.6654 - val_accuracy: 0.8333\n","Epoch 2/10\n","9/9 [==============================] - 3s 361ms/step - loss: 0.6874 - accuracy: 0.7873 - val_loss: 0.6494 - val_accuracy: 0.8333\n","Epoch 3/10\n","9/9 [==============================] - 3s 359ms/step - loss: 0.6728 - accuracy: 0.7873 - val_loss: 0.6484 - val_accuracy: 0.8333\n","Epoch 4/10\n","9/9 [==============================] - 3s 357ms/step - loss: 0.6715 - accuracy: 0.7873 - val_loss: 0.6359 - val_accuracy: 0.8333\n","Epoch 5/10\n","9/9 [==============================] - 3s 369ms/step - loss: 0.6683 - accuracy: 0.7873 - val_loss: 0.6074 - val_accuracy: 0.8333\n","Epoch 6/10\n","9/9 [==============================] - 3s 349ms/step - loss: 0.6750 - accuracy: 0.7873 - val_loss: 0.6127 - val_accuracy: 0.8333\n","Epoch 7/10\n","9/9 [==============================] - 4s 468ms/step - loss: 0.6629 - accuracy: 0.7873 - val_loss: 0.6323 - val_accuracy: 0.8333\n","Epoch 8/10\n","9/9 [==============================] - 3s 387ms/step - loss: 0.6628 - accuracy: 0.7873 - val_loss: 0.6304 - val_accuracy: 0.8333\n","Epoch 9/10\n","9/9 [==============================] - 3s 372ms/step - loss: 0.6645 - accuracy: 0.7873 - val_loss: 0.6130 - val_accuracy: 0.8333\n","Epoch 10/10\n","9/9 [==============================] - 4s 385ms/step - loss: 0.6640 - accuracy: 0.7873 - val_loss: 0.6029 - val_accuracy: 0.8333\n","Epoch 1/10\n","9/9 [==============================] - 6s 388ms/step - loss: 0.6900 - accuracy: 0.6455 - val_loss: 0.6670 - val_accuracy: 0.8667\n","Epoch 2/10\n","9/9 [==============================] - 3s 359ms/step - loss: 0.6799 - accuracy: 0.7836 - val_loss: 0.6326 - val_accuracy: 0.8667\n","Epoch 3/10\n","9/9 [==============================] - 3s 362ms/step - loss: 0.6652 - accuracy: 0.7836 - val_loss: 0.6005 - val_accuracy: 0.8667\n","Epoch 4/10\n","9/9 [==============================] - 3s 353ms/step - loss: 0.6628 - accuracy: 0.7836 - val_loss: 0.6298 - val_accuracy: 0.8667\n","Epoch 5/10\n","9/9 [==============================] - 3s 370ms/step - loss: 0.6659 - accuracy: 0.7836 - val_loss: 0.6316 - val_accuracy: 0.8667\n","Epoch 6/10\n","9/9 [==============================] - 3s 360ms/step - loss: 0.6661 - accuracy: 0.7836 - val_loss: 0.6094 - val_accuracy: 0.8667\n","Epoch 7/10\n","9/9 [==============================] - 3s 374ms/step - loss: 0.6649 - accuracy: 0.7836 - val_loss: 0.5952 - val_accuracy: 0.8667\n","Epoch 8/10\n","9/9 [==============================] - 3s 365ms/step - loss: 0.6744 - accuracy: 0.7836 - val_loss: 0.6244 - val_accuracy: 0.8667\n","Epoch 9/10\n","9/9 [==============================] - 3s 350ms/step - loss: 0.6644 - accuracy: 0.7836 - val_loss: 0.6121 - val_accuracy: 0.8667\n","Epoch 10/10\n","9/9 [==============================] - 3s 366ms/step - loss: 0.6609 - accuracy: 0.7836 - val_loss: 0.6015 - val_accuracy: 0.8667\n","Epoch 1/10\n","9/9 [==============================] - 6s 373ms/step - loss: 0.6915 - accuracy: 0.5261 - val_loss: 0.6762 - val_accuracy: 0.8333\n","Epoch 2/10\n","9/9 [==============================] - 3s 351ms/step - loss: 0.6747 - accuracy: 0.7873 - val_loss: 0.5945 - val_accuracy: 0.8333\n","Epoch 3/10\n","9/9 [==============================] - 3s 344ms/step - loss: 0.8010 - accuracy: 0.7873 - val_loss: 0.6498 - val_accuracy: 0.8333\n","Epoch 4/10\n","9/9 [==============================] - 4s 503ms/step - loss: 0.6749 - accuracy: 0.7873 - val_loss: 0.6592 - val_accuracy: 0.8333\n","Epoch 5/10\n","9/9 [==============================] - 5s 602ms/step - loss: 0.6785 - accuracy: 0.7873 - val_loss: 0.6549 - val_accuracy: 0.8333\n","Epoch 6/10\n","9/9 [==============================] - 5s 597ms/step - loss: 0.6782 - accuracy: 0.7873 - val_loss: 0.6527 - val_accuracy: 0.8333\n","Epoch 7/10\n","9/9 [==============================] - 5s 601ms/step - loss: 0.6737 - accuracy: 0.7873 - val_loss: 0.6458 - val_accuracy: 0.8333\n","Epoch 8/10\n","9/9 [==============================] - 5s 602ms/step - loss: 0.6721 - accuracy: 0.7873 - val_loss: 0.6369 - val_accuracy: 0.8333\n","Epoch 9/10\n","9/9 [==============================] - 5s 610ms/step - loss: 0.6704 - accuracy: 0.7873 - val_loss: 0.6206 - val_accuracy: 0.8333\n","Epoch 10/10\n","9/9 [==============================] - 5s 607ms/step - loss: 0.6596 - accuracy: 0.7873 - val_loss: 0.6051 - val_accuracy: 0.8333\n","Epoch 1/10\n","9/9 [==============================] - 9s 697ms/step - loss: 0.6833 - accuracy: 0.7239 - val_loss: 0.7392 - val_accuracy: 0.6333\n","Epoch 2/10\n","9/9 [==============================] - 5s 603ms/step - loss: 0.6506 - accuracy: 0.8097 - val_loss: 0.7559 - val_accuracy: 0.6333\n","Epoch 3/10\n","9/9 [==============================] - 5s 601ms/step - loss: 0.6493 - accuracy: 0.8097 - val_loss: 0.8041 - val_accuracy: 0.6333\n","Epoch 4/10\n","9/9 [==============================] - 5s 612ms/step - loss: 0.6388 - accuracy: 0.8097 - val_loss: 0.8593 - val_accuracy: 0.6333\n","Epoch 5/10\n","9/9 [==============================] - 5s 587ms/step - loss: 0.6410 - accuracy: 0.8097 - val_loss: 0.8184 - val_accuracy: 0.6333\n","Epoch 6/10\n","9/9 [==============================] - 5s 590ms/step - loss: 0.6413 - accuracy: 0.8097 - val_loss: 0.8569 - val_accuracy: 0.6333\n","Epoch 7/10\n","9/9 [==============================] - 5s 591ms/step - loss: 0.6510 - accuracy: 0.8097 - val_loss: 0.8438 - val_accuracy: 0.6333\n","Epoch 8/10\n","9/9 [==============================] - 5s 597ms/step - loss: 0.6484 - accuracy: 0.8097 - val_loss: 0.7528 - val_accuracy: 0.6333\n","Epoch 9/10\n","9/9 [==============================] - 5s 607ms/step - loss: 0.6517 - accuracy: 0.8097 - val_loss: 0.7570 - val_accuracy: 0.6333\n","Epoch 10/10\n","9/9 [==============================] - 5s 599ms/step - loss: 0.6438 - accuracy: 0.8097 - val_loss: 0.7854 - val_accuracy: 0.6333\n","Epoch 1/10\n","9/9 [==============================] - 9s 664ms/step - loss: 0.6842 - accuracy: 0.7201 - val_loss: 0.6973 - val_accuracy: 0.7333\n","Epoch 2/10\n","9/9 [==============================] - 5s 605ms/step - loss: 0.6960 - accuracy: 0.7985 - val_loss: 0.7034 - val_accuracy: 0.7333\n","Epoch 3/10\n","9/9 [==============================] - 5s 597ms/step - loss: 0.6692 - accuracy: 0.7985 - val_loss: 0.6956 - val_accuracy: 0.7333\n","Epoch 4/10\n","9/9 [==============================] - 5s 598ms/step - loss: 0.6720 - accuracy: 0.7985 - val_loss: 0.6966 - val_accuracy: 0.7333\n","Epoch 5/10\n","9/9 [==============================] - 5s 596ms/step - loss: 0.6676 - accuracy: 0.7985 - val_loss: 0.7003 - val_accuracy: 0.7333\n","Epoch 6/10\n","9/9 [==============================] - 5s 588ms/step - loss: 0.6595 - accuracy: 0.7985 - val_loss: 0.7084 - val_accuracy: 0.7333\n","Epoch 7/10\n","9/9 [==============================] - 5s 597ms/step - loss: 0.6522 - accuracy: 0.7985 - val_loss: 0.7311 - val_accuracy: 0.7333\n","Epoch 8/10\n","9/9 [==============================] - 5s 578ms/step - loss: 0.6505 - accuracy: 0.7985 - val_loss: 0.7394 - val_accuracy: 0.7333\n","Epoch 9/10\n","9/9 [==============================] - 5s 587ms/step - loss: 0.6466 - accuracy: 0.7985 - val_loss: 0.7456 - val_accuracy: 0.7333\n","Epoch 10/10\n","9/9 [==============================] - 5s 598ms/step - loss: 0.6399 - accuracy: 0.7985 - val_loss: 0.7368 - val_accuracy: 0.7333\n","Epoch 1/10\n","9/9 [==============================] - 9s 684ms/step - loss: 0.6889 - accuracy: 0.6952 - val_loss: 0.6602 - val_accuracy: 0.8966\n","Epoch 2/10\n","9/9 [==============================] - 5s 587ms/step - loss: 0.6812 - accuracy: 0.7807 - val_loss: 0.6098 - val_accuracy: 0.8966\n","Epoch 3/10\n","9/9 [==============================] - 5s 591ms/step - loss: 0.6675 - accuracy: 0.7807 - val_loss: 0.5967 - val_accuracy: 0.8966\n","Epoch 4/10\n","9/9 [==============================] - 5s 590ms/step - loss: 0.6657 - accuracy: 0.7807 - val_loss: 0.6138 - val_accuracy: 0.8966\n","Epoch 5/10\n","9/9 [==============================] - 5s 593ms/step - loss: 0.6676 - accuracy: 0.7807 - val_loss: 0.6141 - val_accuracy: 0.8966\n","Epoch 6/10\n","9/9 [==============================] - 5s 594ms/step - loss: 0.6603 - accuracy: 0.7807 - val_loss: 0.5718 - val_accuracy: 0.8966\n","Epoch 7/10\n","9/9 [==============================] - 5s 596ms/step - loss: 0.6667 - accuracy: 0.7807 - val_loss: 0.5858 - val_accuracy: 0.8966\n","Epoch 8/10\n","9/9 [==============================] - 5s 587ms/step - loss: 0.6676 - accuracy: 0.7807 - val_loss: 0.6083 - val_accuracy: 0.8966\n","Epoch 9/10\n","9/9 [==============================] - 5s 589ms/step - loss: 0.6671 - accuracy: 0.7807 - val_loss: 0.6041 - val_accuracy: 0.8966\n","Epoch 10/10\n","9/9 [==============================] - 5s 591ms/step - loss: 0.6641 - accuracy: 0.7807 - val_loss: 0.5977 - val_accuracy: 0.8966\n","Epoch 1/10\n","9/9 [==============================] - 10s 691ms/step - loss: 0.6870 - accuracy: 0.6989 - val_loss: 0.6654 - val_accuracy: 0.8276\n","Epoch 2/10\n","9/9 [==============================] - 5s 602ms/step - loss: 0.7270 - accuracy: 0.7881 - val_loss: 0.6179 - val_accuracy: 0.8276\n","Epoch 3/10\n","9/9 [==============================] - 5s 605ms/step - loss: 0.6598 - accuracy: 0.7881 - val_loss: 0.6564 - val_accuracy: 0.8276\n","Epoch 4/10\n","9/9 [==============================] - 5s 610ms/step - loss: 0.6753 - accuracy: 0.7881 - val_loss: 0.6559 - val_accuracy: 0.8276\n","Epoch 5/10\n","9/9 [==============================] - 5s 606ms/step - loss: 0.6726 - accuracy: 0.7881 - val_loss: 0.6512 - val_accuracy: 0.8276\n","Epoch 6/10\n","9/9 [==============================] - 5s 602ms/step - loss: 0.6717 - accuracy: 0.7881 - val_loss: 0.6428 - val_accuracy: 0.8276\n","Epoch 7/10\n","9/9 [==============================] - 5s 596ms/step - loss: 0.6662 - accuracy: 0.7881 - val_loss: 0.6337 - val_accuracy: 0.8276\n","Epoch 8/10\n","9/9 [==============================] - 5s 611ms/step - loss: 0.6698 - accuracy: 0.7881 - val_loss: 0.6248 - val_accuracy: 0.8276\n","Epoch 9/10\n","9/9 [==============================] - 5s 591ms/step - loss: 0.6627 - accuracy: 0.7881 - val_loss: 0.6208 - val_accuracy: 0.8276\n","Epoch 10/10\n","9/9 [==============================] - 5s 602ms/step - loss: 0.6598 - accuracy: 0.7881 - val_loss: 0.6123 - val_accuracy: 0.8276\n","1/1 [==============================] - 1s 857ms/step\n","0.06896551724137931\n","[[ 0  3  0]\n"," [ 0  2  0]\n"," [ 0 24  0]]\n","              precision    recall  f1-score   support\n","\n","          -1       0.00      0.00      0.00         3\n","           0       0.07      1.00      0.13         2\n","           1       0.00      0.00      0.00        24\n","\n","    accuracy                           0.07        29\n","   macro avg       0.02      0.33      0.04        29\n","weighted avg       0.00      0.07      0.01        29\n","\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["# Train and evaluate the RNN model using k-fold cross-validation\n","folds = range(10,11)\n","\n","for k in folds:\n","    scores = []\n","    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n","    for train_index, val_index in kf.split(TFIDF, label):\n","        X_train, X_test = TFIDF[train_index], TFIDF[val_index]\n","        label = np.array(label)\n","        y_train, y_test = label[train_index], label[val_index]\n","        model = build_model(input_dim=TFIDF.shape[1])\n","        model.fit(np.expand_dims(X_train, axis=2), y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n","\n","    y_pred = model.predict(X_test).astype('int32')\n","    y_pred = y_pred.argmax(axis=1)\n","\n","    print(accuracy_score(y_test, y_pred))\n","    print(confusion_matrix(y_test, y_pred))\n","    print(classification_report(y_test, y_pred))  \n","    #     loss, accuracy = model.evaluate(np.expand_dims(X_test, axis=2), y_test)\n","    #     scores.append(accuracy)\n","    # print('Folds : %d | Cross-validation accuracy : %.3f | Max, Min : %.3f, %.3f' \n","    #         % (k, np.mean(scores), max(scores), min(scores)))\n","    # print(\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"biIObfgV_Gd1"},"source":["## Evaluate the RNN model on the test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gPr1tXQr82bs"},"outputs":[{"ename":"TypeError","evalue":"in user code:\n\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1836, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1824, in run_step  **\n        outputs = model.test_step(data)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1788, in test_step\n        y_pred = self(x, training=False)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 615, in call\n        timesteps = input_shape[0] if self.time_major else input_shape[1]\n\n    TypeError: Exception encountered when calling layer 'lstm_12' (type LSTM).\n    \n    'NoneType' object is not subscriptable\n    \n    Call arguments received by layer 'lstm_12' (type LSTM):\n      â€¢ inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n      â€¢ mask=None\n      â€¢ training=False\n      â€¢ initial_state=None\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mevaluate(np\u001b[39m.\u001b[39;49mexpand_dims(X_test, axis\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m), y_test)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTest accuracy:\u001b[39m\u001b[39m'\u001b[39m, accuracy)\n","File \u001b[1;32mc:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file39bnpnp3.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n","\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1836, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1824, in run_step  **\n        outputs = model.test_step(data)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 1788, in test_step\n        y_pred = self(x, training=False)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 615, in call\n        timesteps = input_shape[0] if self.time_major else input_shape[1]\n\n    TypeError: Exception encountered when calling layer 'lstm_12' (type LSTM).\n    \n    'NoneType' object is not subscriptable\n    \n    Call arguments received by layer 'lstm_12' (type LSTM):\n      â€¢ inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n      â€¢ mask=None\n      â€¢ training=False\n      â€¢ initial_state=None\n"]}],"source":["loss, accuracy = model.evaluate(np.expand_dims(X_test, axis=2), y_test)\n","print('Test accuracy:', accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SFxfN3Qe82bs"},"outputs":[{"ename":"TypeError","evalue":"in user code:\n\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 615, in call\n        timesteps = input_shape[0] if self.time_major else input_shape[1]\n\n    TypeError: Exception encountered when calling layer 'lstm_12' (type LSTM).\n    \n    'NoneType' object is not subscriptable\n    \n    Call arguments received by layer 'lstm_12' (type LSTM):\n      â€¢ inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n      â€¢ mask=None\n      â€¢ training=False\n      â€¢ initial_state=None\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(model\u001b[39m.\u001b[39;49mpredict(np\u001b[39m.\u001b[39;49mexpand_dims(X_test, axis\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)))\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mConfusion matrix:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m conf_matrix \u001b[39m=\u001b[39m confusion_matrix(y_test, y_pred_test)\n","File \u001b[1;32mc:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filee6j6dbg6.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n","\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Madluke\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\layers\\rnn\\lstm.py\", line 615, in call\n        timesteps = input_shape[0] if self.time_major else input_shape[1]\n\n    TypeError: Exception encountered when calling layer 'lstm_12' (type LSTM).\n    \n    'NoneType' object is not subscriptable\n    \n    Call arguments received by layer 'lstm_12' (type LSTM):\n      â€¢ inputs=tf.Tensor(shape=<unknown>, dtype=float32)\n      â€¢ mask=None\n      â€¢ training=False\n      â€¢ initial_state=None\n"]}],"source":["y_pred_test = np.round(model.predict(np.expand_dims(X_test, axis=2)))\n","print('Confusion matrix:')\n","conf_matrix = confusion_matrix(y_test, y_pred_test)\n","print(conf_matrix)\n","class_names = ['negative', 'positive']\n","print('Classification report:')\n","print(classification_report(y_test, y_pred_test, target_names=class_names))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2YjRuDLn82bu"},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Plot the confusion matrix\n","plt.figure(figsize = (5, 5))\n","ax = sns.heatmap(conf_matrix, cmap = 'Blues',\n","                    linecolor = 'white',\n","                    linewidth = 1,\n","                    annot = True,\n","                    fmt = '',\n","                    xticklabels = ['negative', 'positive'],\n","                    yticklabels = ['negative', 'positive'])\n","ax.set_title(\"Confusion Matrix for TFRF with RNN\\n\")\n","ax.set_xlabel(\"\\nPredicted Values\")\n","ax.set_ylabel(\"\\nActual Values\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DdNbP7JE82bw"},"outputs":[],"source":["#K-Fold Cross Validation will iterate k times\n","kFoldCrossValidation = KFold(n_splits=5, random_state=0, shuffle = True)\n","\n","actual_classes = np.empty([0], dtype=int)\n","predicted_classes = np.empty([0], dtype=int)\n","    \n","for train, test in kFoldCrossValidation.split(TFIDF, label):\n","    #Initiate Train and Test Data then transform to TFIDF value. Then copy to new Train and Test variables. \n","    trainData, testData = TFIDF[train], TFIDF[test]\n","    label = np.array(label)\n","    trainData2, testData2 = label[train], label[test]\n","\n","    from keras_preprocessing.sequence import pad_sequences\n","    maxlen = 121 # set the maximum sequence length to 121\n","    trainData = pad_sequences(trainData, maxlen=maxlen)\n","    testData = pad_sequences(testData, maxlen=maxlen)    \n","    \n","    \n","    model = build_model(input_dim=trainData.shape[1])\n","    model.fit(np.expand_dims(trainData, axis=2), trainData2, batch_size=64, epochs=5, verbose=0)\n","    loss, accuracy = model.evaluate(np.expand_dims(testData, axis=2), testData2, verbose=0)\n","    \n","    actual_classes = np.append(actual_classes, label[test])\n","    # predicted_classes = np.round(model.predict(np.expand_dims(testData, axis=2)))\n","    predicted_classes = np.append(predicted_classes, np.round(model.predict(np.expand_dims(testData, axis=2))))\n","   \n","    # scores.append(accuracy)\n","\n","conf_matrix = metrics.confusion_matrix(actual_classes, predicted_classes)\n","rnn_accuracy = metrics.accuracy_score(actual_classes, predicted_classes)\n","precision = metrics.precision_score(actual_classes, predicted_classes, average='macro')\n","recall = metrics.recall_score(actual_classes, predicted_classes, average='macro')\n","f1score = metrics.f1_score(actual_classes, predicted_classes, average='macro')\n","\n","print(\"\\nConfusion Matrix: \\n\", conf_matrix)\n","print(\"------------------------------------------------------------\")\n","print(classification_report(actual_classes, predicted_classes, digits = 4,\n","                           target_names = ['-1', '0', '1']))\n","print(\"------------------------------------------------------------\")\n","print(\"\\nAccuracy : %.3f, Precission : %.3f, Recall : %.3f, F1 Score : %.3f\" %(rnn_accuracy, precision, recall, f1score))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hmoicqoh82bx"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat":4,"nbformat_minor":0}
