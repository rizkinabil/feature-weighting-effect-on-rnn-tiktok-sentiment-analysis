{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sentiment analysis - TFIDF feature weighting with RNN classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Term Weighting = TFIDF`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer #Count Vector Space Model\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn import metrics #Matrix Builder\n",
    "from sklearn.metrics import accuracy_score  \n",
    "from sklearn.model_selection import KFold #Import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_`preprocessed dataset`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>stemming</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>halo min kenapa fitur teratas saya tidak ada m...</td>\n",
       "      <td>['minimal', 'fitur', 'atas', 'minimal', 'tolon...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kenapa gak bisa live yaa</td>\n",
       "      <td>['live']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ingin.tonton.vidio.kupu.kupu.mlm.</td>\n",
       "      <td>['tonton', 'vidio', 'kupu', 'kupu']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tiktok nya kayk kontoll</td>\n",
       "      <td>['tiktok', 'kontoll']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ini akun ketiga mudah¬≤an g di banned lagi</td>\n",
       "      <td>['akun', 'tiga', 'mudah', 'banned']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Tik tok ny langsung gak bisa di bukaa</td>\n",
       "      <td>['bukaa']</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Kkak</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Menyenangkan üòÅ</td>\n",
       "      <td>['senang']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Sangat bagus</td>\n",
       "      <td>['bagus']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Terimakasih tiktok.. Darimu Aku belajar banyaküôèüèª</td>\n",
       "      <td>['terimakasih', 'tiktok', 'dari', 'ajar']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  \\\n",
       "0    halo min kenapa fitur teratas saya tidak ada m...   \n",
       "1                             Kenapa gak bisa live yaa   \n",
       "2                    Ingin.tonton.vidio.kupu.kupu.mlm.   \n",
       "3                              Tiktok nya kayk kontoll   \n",
       "4            Ini akun ketiga mudah¬≤an g di banned lagi   \n",
       "..                                                 ...   \n",
       "279              Tik tok ny langsung gak bisa di bukaa   \n",
       "280                                               Kkak   \n",
       "281                                     Menyenangkan üòÅ   \n",
       "282                                       Sangat bagus   \n",
       "283   Terimakasih tiktok.. Darimu Aku belajar banyaküôèüèª   \n",
       "\n",
       "                                              stemming  label  \n",
       "0    ['minimal', 'fitur', 'atas', 'minimal', 'tolon...     -1  \n",
       "1                                             ['live']      1  \n",
       "2                  ['tonton', 'vidio', 'kupu', 'kupu']      1  \n",
       "3                                ['tiktok', 'kontoll']      1  \n",
       "4                  ['akun', 'tiga', 'mudah', 'banned']      1  \n",
       "..                                                 ...    ...  \n",
       "279                                          ['bukaa']     -1  \n",
       "280                                                 []     -1  \n",
       "281                                         ['senang']      1  \n",
       "282                                          ['bagus']      1  \n",
       "283          ['terimakasih', 'tiktok', 'dari', 'ajar']      1  \n",
       "\n",
       "[284 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\kuliah\\THE ONLY TA THINGS\\DATA\\cleaned_data_review.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "# df = df[df.stemming != '[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content     0\n",
       "stemming    0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_`total label value`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    196\n",
       "-1     74\n",
       " 0     14\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF for feature weighting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split data test data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"stemming\"]\n",
    "y = df[\"label\"] #data target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert text data to TF-IDF feature representation\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "# X_train_vec = tfidf_vectorizer.fit_transform(X_train.apply(lambda x: ' '.join(x)))\n",
    "# X_test_vec = tfidf_vectorizer.transform(X_test.apply(lambda x: ' '.join(x)))\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(use_idf = True ,max_features = 5000)\n",
    "x = tfidf_vect.fit(df['stemming'])\n",
    "TFIDF = x.transform(df['stemming'])\n",
    "TFIDF = TFIDF.toarray()\n",
    "\n",
    "# # Calculate the TF-IDF weights\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# vectorizer.fit(X_train)\n",
    "# x_train_tfidf = vectorizer.transform(X_train).toarray()\n",
    "# x_test_tfidf = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(TFIDF, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(TFIDF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_`Seperate label to its own array`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "for data in df['label']:\n",
    "    label.append(data)\n",
    "kolom = label.pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implement w/ k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=128, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "folds = range(10, 11)\n",
    "for k in folds:\n",
    "    kFoldCrossValidation = KFold(n_splits=k, random_state=0, shuffle = True)\n",
    "    for train, test in kFoldCrossValidation.split(TFIDF, label):\n",
    "        X_train, X_test = TFIDF[train], TFIDF[test]\n",
    "        label = np.array(label)\n",
    "        y_train, y_test = label[train], label[test]\n",
    "        \n",
    "        model = create_model()\n",
    "        model.fit(np.expand_dims(X_train, axis=2), y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
    "        predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    print(classification_report(y_test, predictions, digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = range(2,11)\n",
    "for k in folds:\n",
    "    accuracy=[]\n",
    "    kFoldCrossValidation = KFold(n_splits=k, random_state=0, shuffle = True)\n",
    "    for train, test in kFoldCrossValidation.split(TFIDF, label):\n",
    "        X_train, X_test = TFIDF[train], TFIDF[test]\n",
    "        label = np.array(label)\n",
    "        y_train, y_test = label[train], label[test]\n",
    "\n",
    "\n",
    "        # embedding_size=32\n",
    "        # model = Sequential()\n",
    "        # model.add(Embedding(input_dim=5000, output_dim=embedding_size, input_length=X_train.shape[1]))\n",
    "        # model.add(LSTM(100))\n",
    "        # model.add(Dense(1, activation='sigmoid'))\n",
    "        # model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units=128, input_shape=(X_train.shape[1], 1)))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(units=1, activation='sigmoid'))\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        batch_size = 64\n",
    "        num_epochs = 10\n",
    "        model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs, validation_data=(X_test, y_test))\n",
    "        prediksi = model.predict(X_test)\n",
    "        \n",
    "        accuracy.append(accuracy_score(y_test, prediksi))\n",
    "        \n",
    "    print('Folds : %d | Accuracy : %.3f | Max, Min : %.3f, %.3f' \n",
    "          % (k, Average(accuracy), max(accuracy), min(accuracy)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the k-fold cross-validation iterator\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the RNN model\n",
    "def build_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=128, input_shape=(input_dim, 1)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BE346605E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Folds : 10 | Accuracy : 0.057 | Max, Min : 0.111, 0.022\n",
      "\n",
      "\n",
      "Cross-validation accuracy: 0.057294686511158946\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the RNN model using k-fold cross-validation\n",
    "folds = range(10,11)\n",
    "\n",
    "for k in folds:\n",
    "    scores = []\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train = np.array(y_train)\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "        model = build_model(input_dim=X_train.shape[1])\n",
    "        model.fit(np.expand_dims(X_train_fold, axis=2), y_train_fold, batch_size=64, epochs=5, verbose=0)\n",
    "        loss, accuracy = model.evaluate(np.expand_dims(X_val_fold, axis=2), y_val_fold, verbose=0)\n",
    "        scores.append(accuracy)\n",
    "    print('Folds : %d | Accuracy : %.3f | Max, Min : %.3f, %.3f' \n",
    "            % (k, Average(scores), max(scores), min(scores)))\n",
    "    print(\"\\n\")\n",
    "\n",
    "print('Cross-validation accuracy:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002BE346605E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 87ms/step - loss: 0.7107 - accuracy: 0.0175\n",
      "Test accuracy: 0.017543859779834747\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the RNN model on the test set\n",
    "loss, accuracy = model.evaluate(np.expand_dims(X_test, axis=2), y_test)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_size=32\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(input_dim=5000, output_dim=embedding_size))\n",
    "# model.add(LSTM(100))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=128, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 64\n",
    "# num_epochs = 5\n",
    "# model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs, verbose=1)\n",
    "\n",
    "model.fit(np.expand_dims(X_train, axis=2), y_train, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion matrix:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "class_names = ['negative', 'neutral', 'positive']\n",
    "report = classification_report(y_test, y_pred, target_names=class_names)\n",
    "print('Classification report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize = (5, 5))\n",
    "ax = sns.heatmap(conf_matrix, cmap = 'Blues',\n",
    "                    linecolor = 'white',\n",
    "                    linewidth = 1,\n",
    "                    annot = True,\n",
    "                    fmt = '',\n",
    "                    xticklabels = ['negative', 'neutral', 'positive'],\n",
    "                    yticklabels = ['negative', 'neutral', 'positive'])\n",
    "ax.set_title(\"Confusion Matrix for TFIDF\\n\")\n",
    "ax.set_xlabel(\"\\nPredicted Values\")\n",
    "ax.set_ylabel(\"\\nActual Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
